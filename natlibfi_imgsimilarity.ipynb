{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental historical illustration similarity comparison\n",
    "\n",
    "Scripts to check whether target image is similar to the given set of target images.\n",
    "\n",
    "Adaptation of work done at: https://douglasduhaime.com/posts/identifying-similar-images-with-tensorflow.html \n",
    "\n",
    "\n",
    "\n",
    "Acknowledgments\n",
    "\n",
    "<table><tr><td>\n",
    "<img src=\"https://digi.kansalliskirjasto.fi/images/sosiaali_en.png\" alt=\"European Regional Development Fund\" height=\"110\">\n",
    "</td><td>\n",
    "<img src=\"https://digi.kansalliskirjasto.fi/images/en_EU_rgb.png\" alt=\"Leverage from the EU 2014-2020\" height=\"110\"></td>\n",
    "</tr></table>\n",
    "\n",
    "#### Setup \n",
    "\n",
    "E.g. Anaconda installation is useful to include all needed python modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running via Google Colaboratory, you might need these to install some extra modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q annoy\n",
    "!curl https://raw.githubusercontent.com/TuulaP/natlibfi_imgsimilarity/master/classify_nlf.py?token=AAZJIPX47Y2H46QYSHK52A2524NUQ > classify_nlf.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Image similarity code\n",
    "\n",
    "Basic imports \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "import codecs\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "from nltk import ngrams\n",
    "from scipy import spatial\n",
    "from annoy import AnnoyIndex\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#module_path = os.path.abspath(os.path.join('.'))\n",
    "#if module_path not in sys.path:\n",
    "#    sys.path.append(module_path)\n",
    "\n",
    "#for notebook:\n",
    "%tensorflow_version 1.x\n",
    "    \n",
    "from classify_nlf import run_inference_on_images\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "dims = 2048\n",
    "n_nearest_neighbors = 5   # control the number of neighbors, increase\n",
    "trees = 10000\n",
    "NPZDIR = \"./tmp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial picture vectors to index\n",
    "\n",
    "def initializepicvectors():\n",
    "\n",
    "    # location where the feature descriptions of images exist.\n",
    "    infiles = glob.glob(NPZDIR + '*.npz')\n",
    "\n",
    "    for file_index, i in enumerate(infiles):\n",
    "        file_vector = np.loadtxt(i)\n",
    "        file_name = os.path.basename(i).split('.')[0]\n",
    "        file_index_to_file_name[file_index] = file_name\n",
    "        file_index_to_file_vector[file_index] = file_vector\n",
    "        t.add_item(file_index, file_vector)\n",
    "    t.build(trees)\n",
    "\n",
    "    return [t, file_index_to_file_name, file_index_to_file_vector]\n",
    "\n",
    "\n",
    "# adding stuff to index is slow, but retrieval fast\n",
    "\n",
    "def additemtoindex(item, t, file_index_to_file_name, file_index_to_file_vector):\n",
    "\n",
    "    # see: https://github.com/spotify/annoy/issues/174#issuecomment-252616632\n",
    "    #print(\"Unbuilding index to add one.\")\n",
    "    t.unbuild()\n",
    "    #print(\"adding new one {0}\".format(item))\n",
    "\n",
    "    max = len(file_index_to_file_name)\n",
    "    file_vector = np.loadtxt(item)\n",
    "    t.add_item(max, file_vector)\n",
    "\n",
    "    item = os.path.basename(item).split('.')[0]\n",
    "    file_index_to_file_name[max] = item\n",
    "    file_index_to_file_vector[max] = file_vector\n",
    "\n",
    "    # print(\"Rebuilding...\")\n",
    "    t.build(trees)\n",
    "\n",
    "    return [t, file_index_to_file_name, file_index_to_file_vector]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the targetimage 'miimage' and compares it to the already 'known' images in order\n",
    "# to find neighbors, which mean pictures that seem similar\n",
    "\n",
    "def findsimilars(miimage, file_index_to_file_name, file_index_to_file_vector, t):\n",
    "    images = []\n",
    "    images.append(miimage)\n",
    "\n",
    "    output_dir = \"./tmp\"\n",
    "\n",
    "    (image_to_labels, npzfile) = run_inference_on_images(\n",
    "        images, output_dir)  # this creates npz\n",
    "\n",
    "    # with open(\"image_to_labels.json\", \"w\") as img_to_labels_out:\n",
    "    #            print(\"Dumping {0}\".format(image_to_labels))\n",
    "    #            json.dump(image_to_labels, img_to_labels_out)\n",
    "\n",
    "    DIR = \"./data/\"\n",
    "    target = DIR + miimage + \".npz\"\n",
    "\n",
    "    targetbase = target.replace(\".jpg.npz\", \"\").replace(DIR, \"\")\n",
    "    print(\"Targetbase:{0}\".format(targetbase))\n",
    "\n",
    "    (t, file_index_to_file_name, file_index_to_file_vector) = additemtoindex(\n",
    "        NPZDIR + npzfile, t, file_index_to_file_name, file_index_to_file_vector)\n",
    " #\n",
    "    # etsittava _fk03927_1909-03_3_pg115_498017_pic01 , [0.18322894 0.62656009 0.30706945 ... 0.02660679 0.00194689 0.1605511 ]\n",
    "    # Naapuri _fk03927_1909-03_3_pg115_498017_pic01 , [0.18322894 0.62656009 0.30706945 ... 0.02660679 0.00194689 0.1605511 ]\n",
    "\n",
    "    named_nearest_neighbors = []\n",
    "\n",
    "    allfilenames = file_index_to_file_name.keys()\n",
    "\n",
    "    for i in allfilenames:\n",
    "\n",
    "        master_file_name = file_index_to_file_name[i]\n",
    "        master_vector = file_index_to_file_vector[i]\n",
    "\n",
    "        if (master_file_name in targetbase):  # no point to verify itself\n",
    "            continue\n",
    "        # else:\n",
    "            #print(\"Calculating neighbourhood relations :)\")\n",
    "            # sys.exit(1)\n",
    "\n",
    "        named_nearest_neighbors = []\n",
    "        nearest_neighbors = t.get_nns_by_item(i, n_nearest_neighbors)\n",
    "\n",
    "        for j in nearest_neighbors:\n",
    "\n",
    "            neighbor_file_name = file_index_to_file_name[j]\n",
    "            neighbor_file_vector = file_index_to_file_vector[j]\n",
    "\n",
    "            similarity = 1 - \\\n",
    "                spatial.distance.cosine(master_vector, neighbor_file_vector)\n",
    "            rounded_similarity = int((similarity * 10000)) / 10000.0\n",
    "\n",
    "            # 0.7599:  # 0.8, how much 'similarity' there should be.\n",
    "            if rounded_similarity > 0.7500:\n",
    "                named_nearest_neighbors.append({\n",
    "                    'filename': neighbor_file_name,\n",
    "                    'similarity': rounded_similarity\n",
    "                })\n",
    "\n",
    "        # for neigh in named_nearest_neighbors:\n",
    "        #    #print(\"!\", neigh)\n",
    "        #    simis = len(named_nearest_neighbors)\n",
    "        #    print(\"Closest similar: {2} --- {0}>>> {1} kpl; near.neigh: \".format(\n",
    "        #        named_nearest_neighbors, simis, master_file_name))\n",
    "\n",
    "        with open('nearest_neighbors/' + master_file_name + '.json', 'w') as out:\n",
    "            json.dump(named_nearest_neighbors, out)\n",
    "            #print(\"{0} written.\".format(master_file_name+'.json'))\n",
    "\n",
    "    #shutil.move(npzfile, \"nlf_vectors/\")\n",
    "    #print(\"{0} moved with other vectors.\".format(npzfile))\n",
    "\n",
    "    return [named_nearest_neighbors, t, file_index_to_file_name, file_index_to_file_vector]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in file_index 41\n",
      "Parsing 0 data/search-result-preview_019.jpg \n",
      "\n",
      "Targetbase:data/search-result-preview_019\n",
      "For targetimg: data/search-result-preview_019.jpg, found 3 neighbors\n",
      "Neighbours are:  [{'filename': 'search-result-preview_020', 'similarity': 1.0}, {'filename': 'search-result-preview_015', 'similarity': 0.893}, {'filename': 'search-result-preview_003', 'similarity': 0.8817}]\n",
      "All done.\n"
     ]
    }
   ],
   "source": [
    "# Give target image as command line parameter and get json file as result.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    import sys\n",
    "    targetimg = \"data/search-result-preview_019.jpg\"  #sys.argv[1]\n",
    "\n",
    "    t = AnnoyIndex(dims, metric='angular')\n",
    "\n",
    "    # data structures\n",
    "    file_index_to_file_name = {}\n",
    "    file_index_to_file_vector = {}\n",
    "    chart_image_positions = {}\n",
    "\n",
    "    initializepicvectors()\n",
    "\n",
    "    # the initial setup\n",
    "    #exampleset = glob.glob('data/*.jpg')\n",
    "    exampleset = []\n",
    "    exampleset.append(targetimg)\n",
    "\n",
    "    for targetimg in exampleset:  # ('hlo.jpg', 'orna2.jpg'):\n",
    "\n",
    "        print(\"Items in file_index {0}\".format(len(file_index_to_file_name)))\n",
    "\n",
    "        (naapur, t, file_index_to_file_name, file_index_to_file_vector) = findsimilars(targetimg, file_index_to_file_name,\n",
    "                                                                                       file_index_to_file_vector, t)\n",
    "        print(\"For targetimg: {0}, found {1} neighbors\".format(targetimg, len(naapur)))\n",
    "        print(\"Neighbours are: \", naapur)\n",
    "\n",
    "    print(\"All done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
